{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Data Preview:\n",
      "   code_pro   wilaya                            field  \\\n",
      "0  P6B3R8CC  Algiers                              NaN   \n",
      "1  LPC2SE3W  Algiers           Services Ã  la personne   \n",
      "2  DBX8Y5D7    Batna  Conseil, Expertise et formation   \n",
      "3  PYC53DLT    Msila           Services Ã  la personne   \n",
      "4  TLLSNCC9  Algiers           Services Ã  la personne   \n",
      "\n",
      "                                            activity  \\\n",
      "0  Technicien de Maintenance du matÃ©riel PrÃ©press...   \n",
      "1                Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª ØªØ£Ø´ÙŠØ±Ø© Ùˆ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø²Ø¨Ø§Ø¦Ù†   \n",
      "2          Ù…Ø³ØªØ´Ø§Ø± Ù…Ø®ØªØµ Ø¨ØªØ£Ø´ÙŠØ±Ø§Øª Ø§Ù„Ø³ÙØ± Ùˆ Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ù‡Ø¬Ø±Ø©   \n",
      "3                                Ø§Ù„Ø±Ø³Ù… Ø¨Ø§Ù„Ø²ÙŠØª ÙˆØ§Ù„Ø±Ù…Ù„   \n",
      "4  Dessinateur projeteur en travaux publics et su...   \n",
      "\n",
      "                                         description  \n",
      "0  Le service PrÃ©presse est Ã©quipÃ© des machines C...  \n",
      "1  Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª ØªØ£Ø´ÙŠØ±Ø© ÙˆØ­Ø¬Ø² Ù…ÙˆØ§Ø¹ÙŠØ¯ ÙˆØ§Ù„ØªÙˆØ¬Ø¨Ù‡ Ø§Ù„Ø²Ø¨Ø§...  \n",
      "2  ØªÙ‚Ø¯ÙŠÙ… Ø§Ø³ØªØ´Ø§Ø±Ø§Øª ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„Ø³ÙØ± Ùˆ Ø§Ù„Ù‡Ø¬Ø±Ø© Ù…Ù† Ø£Ø¬Ù„ Ù…...  \n",
      "3    Ø±Ø³Ù… Ø£Ø´Ø®Ø§Øµ ÙˆØ·Ø¨ÙŠØ¹Ø© Ùˆ Ù…Ù†Ø§Ø¸Ø± ØµØ­Ø±Ø§ÙˆÙŠØ©  Ø¨Ø§Ù„Ø²ÙŠØª ÙˆØ§Ù„Ø±Ù…Ù„  \n",
      "4  dessinateur projeteur en travaux publics (bÃ¢ti...  \n",
      "\n",
      "ðŸŽ¯ Unique values in 'field':\n",
      "Services Ã  la personne\n",
      "Conseil, Expertise et formation\n",
      "Services de loisirs et de rÃ©crÃ©ation\n",
      "Prestations Ã  domicile\n",
      "Services aux entreprises\n",
      "Services numÃ©riques et activitÃ©s connexes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file (change 'your_file.xlsx' to your actual file)\n",
    "file_path = \"activities-propositions-anae-18-02-2025 (1).xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"\\nðŸ“Œ Data Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Specify the column name to get unique values\n",
    "column_name = \"field\"  # Change this to your desired column\n",
    "\n",
    "if column_name in df.columns:\n",
    "    unique_values = df[column_name].dropna().unique()\n",
    "    print(f\"\\nðŸŽ¯ Unique values in '{column_name}':\")\n",
    "    print(\"\\n\".join(map(str, unique_values)))\n",
    "else:\n",
    "    print(f\"\\nâŒ Column '{column_name}' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Step 1: Load the pre-trained model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Step 1: Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 2: Define the sentence and paragraph\n",
    "sentence = \"content creator\"\n",
    "paragraph = (\"I have a lot of pages in Instagram, Facebook, and so on. \"\n",
    "             \"Also, I use YouTube and upload my videos to make people like me.\")\n",
    "\n",
    "# Step 3: Generate embeddings for the sentence and paragraph\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "paragraph_embedding = model.encode(paragraph, convert_to_tensor=True)\n",
    "\n",
    "# Step 4: Compute cosine similarity\n",
    "cosine_score = util.pytorch_cos_sim(sentence_embedding, paragraph_embedding).item()\n",
    "\n",
    "# Step 5: Print the result\n",
    "print(f\"Cosine Similarity between '{sentence}' and the paragraph: {cosine_score:.4f}\")\n",
    "\n",
    "# Optional: Interpret the result based on a threshold\n",
    "if cosine_score > 0.7:\n",
    "    print(\"The sentence and paragraph are highly similar.\")\n",
    "elif cosine_score > 0.5:\n",
    "    print(\"The sentence and paragraph share some common context.\")\n",
    "else:\n",
    "    print(\"The sentence and paragraph are not related.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
