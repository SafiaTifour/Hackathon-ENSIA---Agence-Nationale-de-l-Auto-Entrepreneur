{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Data Preview:\n",
      "   code_pro   wilaya                            field  \\\n",
      "0  P6B3R8CC  Algiers                              NaN   \n",
      "1  LPC2SE3W  Algiers           Services à la personne   \n",
      "2  DBX8Y5D7    Batna  Conseil, Expertise et formation   \n",
      "3  PYC53DLT    Msila           Services à la personne   \n",
      "4  TLLSNCC9  Algiers           Services à la personne   \n",
      "\n",
      "                                            activity  \\\n",
      "0  Technicien de Maintenance du matériel Prépress...   \n",
      "1                معالجة ملفات تأشيرة و خدمات الزبائن   \n",
      "2          مستشار مختص بتأشيرات السفر و برامج الهجرة   \n",
      "3                                الرسم بالزيت والرمل   \n",
      "4  Dessinateur projeteur en travaux publics et su...   \n",
      "\n",
      "                                         description  \n",
      "0  Le service Prépresse est équipé des machines C...  \n",
      "1  معالجة ملفات تأشيرة وحجز مواعيد والتوجبه الزبا...  \n",
      "2  تقديم استشارات في مجال السفر و الهجرة من أجل م...  \n",
      "3    رسم أشخاص وطبيعة و مناظر صحراوية  بالزيت والرمل  \n",
      "4  dessinateur projeteur en travaux publics (bâti...  \n",
      "\n",
      "🎯 Unique values in 'field':\n",
      "Services à la personne\n",
      "Conseil, Expertise et formation\n",
      "Services de loisirs et de récréation\n",
      "Prestations à domicile\n",
      "Services aux entreprises\n",
      "Services numériques et activités connexes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file (change 'your_file.xlsx' to your actual file)\n",
    "file_path = \"activities-propositions-anae-18-02-2025 (1).xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"\\n📌 Data Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Specify the column name to get unique values\n",
    "column_name = \"field\"  # Change this to your desired column\n",
    "\n",
    "if column_name in df.columns:\n",
    "    unique_values = df[column_name].dropna().unique()\n",
    "    print(f\"\\n🎯 Unique values in '{column_name}':\")\n",
    "    print(\"\\n\".join(map(str, unique_values)))\n",
    "else:\n",
    "    print(f\"\\n❌ Column '{column_name}' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Step 1: Load the pre-trained model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Step 1: Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 2: Define the sentence and paragraph\n",
    "sentence = \"content creator\"\n",
    "paragraph = (\"I have a lot of pages in Instagram, Facebook, and so on. \"\n",
    "             \"Also, I use YouTube and upload my videos to make people like me.\")\n",
    "\n",
    "# Step 3: Generate embeddings for the sentence and paragraph\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "paragraph_embedding = model.encode(paragraph, convert_to_tensor=True)\n",
    "\n",
    "# Step 4: Compute cosine similarity\n",
    "cosine_score = util.pytorch_cos_sim(sentence_embedding, paragraph_embedding).item()\n",
    "\n",
    "# Step 5: Print the result\n",
    "print(f\"Cosine Similarity between '{sentence}' and the paragraph: {cosine_score:.4f}\")\n",
    "\n",
    "# Optional: Interpret the result based on a threshold\n",
    "if cosine_score > 0.7:\n",
    "    print(\"The sentence and paragraph are highly similar.\")\n",
    "elif cosine_score > 0.5:\n",
    "    print(\"The sentence and paragraph share some common context.\")\n",
    "else:\n",
    "    print(\"The sentence and paragraph are not related.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
